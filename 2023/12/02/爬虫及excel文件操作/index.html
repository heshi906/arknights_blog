<!DOCTYPE html><html lang="en" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>爬虫及excel文件操作 | 大嗨阔(成长度1%)</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/","search":{"preload":true,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"copy"}}</script><link type="text/css" rel="stylesheet" href="/lib/encrypt/hbe.style.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>:root {
 --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
 --light-background: url('/img/bk.jpg');
 --theme-encrypt-confirm: 'confirm'
}</style><script defer src="/js/arknights.js"></script><script defer src="/js/search.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/lib/encrypt/hbe.js"></script><script async src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);document.addEventListener('pjax:success', _ => bszCaller.fetch(
 "//busuanzi.ibruce.info/busuanzi?jsonpCallback=BusuanziCallback", a => {
  bszTag.texts(a),
  bszTag.shows()
}));reset()})</script><meta name="generator" content="Hexo 7.0.0"></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li><li class="navItem"><a class="navBlock" href="/links/"><span class="navItemTitle">Links</span></a></li><li class="navItem"><a class="navBlock" href="/about/"><span class="navItemTitle">About</span></a></li><li class="navItem"><a class="navBlock" href="/games/"><span class="navItemTitle">Games</span></a></li><li class="navItem"><a class="navBlock" href="/daohang/"><span class="navItemTitle">导航</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>爬虫及excel文件操作</h1><div id="post-info"><span>First Post: <div class="control"><time datetime="2023-12-02T07:42:09.000Z" id="date"> 2023-12-02</time></div></span><br><span>Last Update: <div class="control"><time datetime="2023-12-05T12:46:08.072Z" id="updated"> 2023-12-05</time></div></span><br><span>Word Count: <div class="control">1.3k</div></span><br><span>Read Time: <div class="control">6 min</div></span><br><span id="busuanzi_container_page_pv">Page View: <span class="control" id="busuanzi_value_page_pv">loading...</span></span></div></div><hr><div id="post-content"><h1 id="爬我的网站"><a href="#爬我的网站" class="headerlink" title="爬我的网站"></a>爬我的网站</h1><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">import pandas as pd<br>from bs4 import BeautifulSoup<br>import requests<br><br>page=requests.get(&quot;http://47.99.105.206:8080/&quot;)<br>context=page.text<br><br>soup = BeautifulSoup(context, &#x27;html.parser&#x27;)<br>td_elements = soup.find_all(&#x27;td&#x27;, &#123;&#x27;bgcolor&#x27;: &#x27;#eeeeee&#x27;&#125;)<br><br># 初始化变量以保存学号和分数<br>student_id = None<br>score = None<br>data = &#123;&#125;<br>xuehao = []<br>fenshu = []<br>for i, td_element in enumerate(td_elements):<br>    if i%18 != 17 and i%18 != 16:<br>        continue<br>    num = i // 18<br>    if i % 18 == 16:  # 根据示例中的位置确定分数所在的索引<br>        score = td_element.text.strip()<br>        fenshu.append(score)<br>    if i % 18 == 17:<br>        student_id = td_element.text.strip()<br>        xuehao.append(student_id)<br><br># 打印学号和分数<br>data[&quot;学号&quot;]=xuehao<br>data[&quot;分数&quot;]=fenshu<br><br># 将字典转换为DataFrame<br>df = pd.DataFrame(data)<br><br># 指定Excel文件路径<br>excel_file_path = &#x27;分数.xlsx&#x27;<br><br># 将DataFrame写入Excel文件<br>df.to_excel(excel_file_path, index=False, engine=&#x27;openpyxl&#x27;)<br><br>print(f&#x27;DataFrame写入Excel文件成功，文件路径为: &#123;excel_file_path&#125;&#x27;)<br></code></pre></td></tr></table></figure>

<h2 id="用到的库"><a href="#用到的库" class="headerlink" title="用到的库"></a>用到的库</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">requests：拿取html用<br>BeautifulSoup：解析html<br>pandas：数据处理到excel<br></code></pre></td></tr></table></figure>

<h2 id="pandas基础操作"><a href="#pandas基础操作" class="headerlink" title="pandas基础操作"></a>pandas基础操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">import pandas as pd<br><br># 读取Excel文件<br>df = pd.read_excel(&#x27;文件路径.xlsx&#x27;)<br><br># 写入Excel文件<br>df.to_excel(&#x27;输出文件.xlsx&#x27;, index=False)<br><br><br><br><br></code></pre></td></tr></table></figure>

<h2 id="requests基本操作"><a href="#requests基本操作" class="headerlink" title="requests基本操作"></a>requests基本操作</h2><p><strong>发送 GET 请求：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">python<br>import requests<br><br>response = requests.get(&#x27;https://example.com&#x27;)<br></code></pre></td></tr></table></figure>

<p><strong>发送 POST 请求：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">python<br>import requests<br><br>data = &#123;&#x27;key1&#x27;: &#x27;value1&#x27;, &#x27;key2&#x27;: &#x27;value2&#x27;&#125;<br>response = requests.post(&#x27;https://example.com/post&#x27;, data=data)<br></code></pre></td></tr></table></figure>

<p><strong>发送带参数的 GET 请求：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">python<br>import requests<br><br>params = &#123;&#x27;param1&#x27;: &#x27;value1&#x27;, &#x27;param2&#x27;: &#x27;value2&#x27;&#125;<br>response = requests.get(&#x27;https://example.com/get&#x27;, params=params)<br></code></pre></td></tr></table></figure>

<p><strong>处理响应：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">python<br>import requests<br><br>response = requests.get(&#x27;https://example.com&#x27;)<br><br># 获取响应状态码<br>status_code = response.status_code<br><br># 获取响应内容<br>content = response.text<br></code></pre></td></tr></table></figure>

<p><strong>处理 JSON 响应：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">python<br>import requests<br><br>response = requests.get(&#x27;https://api.example.com/data&#x27;)<br><br># 将JSON响应转换为字典<br>json_data = response.json()<br></code></pre></td></tr></table></figure>

<p><strong>自定义请求头：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">python<br>import requests<br><br>headers = &#123;&#x27;User-Agent&#x27;: &#x27;my-app/1.0&#x27;&#125;<br>response = requests.get(&#x27;https://example.com&#x27;, headers=headers)<br></code></pre></td></tr></table></figure>

<p><strong>处理异常：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">python<br>import requests<br><br>try:<br>    response = requests.get(&#x27;https://example.com&#x27;)<br>    response.raise_for_status()  # 检查是否有错误状态码<br>except requests.exceptions.HTTPError as errh:<br>    print(f&quot;HTTP Error: &#123;errh&#125;&quot;)<br>except requests.exceptions.ConnectionError as errc:<br>    print(f&quot;Error Connecting: &#123;errc&#125;&quot;)<br>except requests.exceptions.RequestException as err:<br>    print(f&quot;An unexpected error occurred: &#123;err&#125;&quot;)<br></code></pre></td></tr></table></figure>

<p><strong>文件上传：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">python<br>import requests<br><br>files = &#123;&#x27;file&#x27;: (&#x27;filename.txt&#x27;, open(&#x27;filename.txt&#x27;, &#x27;rb&#x27;))&#125;<br>response = requests.post(&#x27;https://example.com/upload&#x27;, files=files)<br></code></pre></td></tr></table></figure>

<h2 id="BeautifulSoup示例"><a href="#BeautifulSoup示例" class="headerlink" title="BeautifulSoup示例"></a>BeautifulSoup示例</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">from bs4 import BeautifulSoup<br><br># HTML示例字符串<br>html = &quot;&quot;&quot;<br>&lt;html&gt;<br>&lt;head&gt;<br>    &lt;title&gt;BeautifulSoup Example&lt;/title&gt;<br>&lt;/head&gt;<br>&lt;body&gt;<br>    &lt;div id=&quot;content&quot;&gt;<br>        &lt;h1&gt;Sample Page&lt;/h1&gt;<br>        &lt;p class=&quot;paragraph&quot;&gt;This is a sample paragraph.&lt;/p&gt;<br>        &lt;ul&gt;<br>            &lt;li&gt;Item 1&lt;/li&gt;<br>            &lt;li&gt;Item 2&lt;/li&gt;<br>            &lt;li&gt;Item 3&lt;/li&gt;<br>        &lt;/ul&gt;<br>    &lt;/div&gt;<br>&lt;/body&gt;<br>&lt;/html&gt;<br>&quot;&quot;&quot;<br><br># 创建BeautifulSoup对象<br>soup = BeautifulSoup(html, &#x27;html.parser&#x27;)<br><br># 查找特定标签<br>title_tag = soup.title<br>h1_tag = soup.h1<br><br># 获取标签内容<br>title_text = title_tag.text<br>h1_text = h1_tag.text<br><br># 查找所有段落标签<br>paragraphs = soup.find_all(&#x27;p&#x27;)<br><br># 遍历并输出段落内容<br>for p in paragraphs:<br>    print(&quot;Paragraph:&quot;, p.text)<br><br># 查找并输出列表项<br>list_items = soup.find_all(&#x27;li&#x27;)<br>for li in list_items:<br>    print(&quot;List Item:&quot;, li.text)<br><br></code></pre></td></tr></table></figure>

<h1 id="爬新闻头条"><a href="#爬新闻头条" class="headerlink" title="爬新闻头条"></a>爬新闻头条</h1><h2 id="完整代码-1"><a href="#完整代码-1" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">from bs4 import BeautifulSoup<br>import requests<br><br>page=requests.get(&quot;https://top.baidu.com/board?platform=pc&amp;tab=homepage&amp;sa=pc_index_homepage_all&quot;)<br>context=page.text<br>soup=BeautifulSoup(context,&#x27;html.parser&#x27;)<br>titles = soup.find_all(&#x27;div&#x27;, class_=&#x27;c-single-text-ellipsis&#x27;)<br>for i,title in enumerate(titles):<br>    if i % 2==1 or i &gt;21:<br>        continue<br>    print(i//2,title.text)<br></code></pre></td></tr></table></figure>

<h2 id="学到的内容"><a href="#学到的内容" class="headerlink" title="学到的内容"></a>学到的内容</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">titles = soup.find_all(&#x27;div&#x27;, class_=&#x27;c-single-text-ellipsis&#x27;)<br><br>for i,title in enumerate(titles):<br></code></pre></td></tr></table></figure>

<h1 id="爬百度百科"><a href="#爬百度百科" class="headerlink" title="爬百度百科"></a>爬百度百科</h1><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">import requests<br>import os<br>from bs4 import BeautifulSoup<br>from tkinter import Tk, Label, PhotoImage<br>from PIL import Image, ImageTk<br>import json<br><br>def download_image(url, save_path, file_name):<br>    try:<br>        # 发送请求获取图片数据<br>        response = requests.get(url)<br>        response.raise_for_status()  # 检查请求是否成功<br>        try:<br>            os.makedirs(&quot;picture&quot;)<br>        except:<br>            pass<br>        # 拼接保存路径和文件名<br>        file_path = os.path.join(save_path, file_name)<br><br>        # 将图片数据保存到文件<br>        with open(file_path, &#x27;wb&#x27;) as img_file:<br>            img_file.write(response.content)<br><br>        print(f&quot;图片已成功下载到: &#123;file_path&#125;&quot;)<br><br>    except requests.exceptions.RequestException as e:<br>        print(f&quot;下载图片时发生错误: &#123;e&#125;&quot;)<br><br><br>def show_actor(name, image_path):<br>    try:<br>        root = Tk()<br>        root.title(&quot;演员展示&quot;)<br><br>        # 显示演员名字<br>        label_name = Label(root, text=name, font=(&quot;Helvetica&quot;, 16))<br>        label_name.pack()<br><br>        # 显示演员图片<br>        img = Image.open(image_path)<br>        img = img.resize((400, 400), Image.LANCZOS)<br>        photo = ImageTk.PhotoImage(img)<br><br>        label_image = Label(root, image=photo)<br>        label_image.image = photo  # 保持引用，避免被垃圾回收<br>        label_image.pack()<br><br>        root.mainloop()<br>    except:<br>        print(&quot;暂无该演员图片&quot;)<br>        pass<br><br><br>def getinfo():<br>    actor_name=[]<br>    url = &quot;https://baike.baidu.com/item/%E7%8B%82%E9%A3%99&quot;<br>    response = requests.get(url)<br>    soup = BeautifulSoup(response.text, &#x27;html.parser&#x27;)<br>    table = soup.find_all(&#x27;div&#x27;, class_=&#x27;actorItem_ptZyH&#x27;)<br>    for actor in table:<br>        actor_info = actor.find_all(&quot;span&quot;, class_=&quot;text_argYK&quot;)<br>        name = actor_info[0].text<br>        charactor = actor_info[1].text<br>        print(&quot;演员姓名：&quot;, name)<br>        print(&quot;演员角色：&quot;, charactor)<br>        actor_name.append(name+&quot; 饰 &quot;+charactor)<br>        actor_pic = actor.find(&quot;div&quot;, class_=&quot;coverPic_e6cDt&quot;).find(&quot;img&quot;).get(&quot;src&quot;)<br>        if actor_pic != &quot;https://baikebcs.bdimg.com/baike-react/lemma/actor.png&quot;:<br>            download_image(actor_pic, &quot;./picture/&quot;, name + &quot;.png&quot;)<br>    with open(&quot;name.json&quot;, &#x27;w&#x27;) as f:1<br>        json.dump(actor_name,f)<br><br>def show():<br>    with open(&quot;name.json&quot;, &#x27;r&#x27;) as f:<br>        actor_name=json.load(f)<br>    for name in actor_name:<br>        print(name)<br>print(&quot;[1]爬取《狂飙》所有演员图片&quot;)<br>print(&quot;[2]查看演员列表&quot;)<br>print(&quot;[3]查看图片&quot;)<br>while 1:<br>    choice = input(&quot;请输入选择&quot;)<br>    if choice == &quot;1&quot;:<br>        getinfo()<br>    if choice == &quot;2&quot;:<br>        show()<br>    if choice == &quot;3&quot;:<br>        name = input(&quot;请输入演员名&quot;)<br>        show_actor(name, f&quot;./picture/&#123;name&#125;.png&quot;)<br></code></pre></td></tr></table></figure>
<div id="paginator"></div></div><div id="post-footer"><div id="pages" style="justify-content: flex-end"><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2023/11/20/%E5%A4%87%E5%BF%98/%E6%90%AD%E5%BB%BA%E7%BD%91%E7%AB%99%E7%94%A8%E5%88%B0%E7%9A%84%E7%AB%99/">搭建网站用到的站 Prev →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="/favicon.ico" alt="Logo"></a><h1 id="Dr"><a href="/">heshi906</a></h1><div id="description"><p>大概只有漫不经心 才是唯一的解药</p></div><div id="social-links"><a class="social" target="_blank" rel="noopener" href="https://github.com/heshi906"><i class="fab fa-github" alt="GitHub"></i></a></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%88%AC%E6%88%91%E7%9A%84%E7%BD%91%E7%AB%99"><span class="toc-number">1.</span> <span class="toc-text">爬我的网站</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="toc-number">1.1.</span> <span class="toc-text">完整代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8%E5%88%B0%E7%9A%84%E5%BA%93"><span class="toc-number">1.2.</span> <span class="toc-text">用到的库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pandas%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C"><span class="toc-number">1.3.</span> <span class="toc-text">pandas基础操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#requests%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="toc-number">1.4.</span> <span class="toc-text">requests基本操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSoup%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.5.</span> <span class="toc-text">BeautifulSoup示例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%88%AC%E6%96%B0%E9%97%BB%E5%A4%B4%E6%9D%A1"><span class="toc-number">2.</span> <span class="toc-text">爬新闻头条</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-1"><span class="toc-number">2.1.</span> <span class="toc-text">完整代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E5%88%B0%E7%9A%84%E5%86%85%E5%AE%B9"><span class="toc-number">2.2.</span> <span class="toc-text">学到的内容</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%88%AC%E7%99%BE%E5%BA%A6%E7%99%BE%E7%A7%91"><span class="toc-number">3.</span> <span class="toc-text">爬百度百科</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">3.1.</span> <span class="toc-text">代码</span></a></li></ol></li></ol></div></div><footer><nobr>Published with <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> Theme <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> by <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>